{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Protocols for Fair Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from problem import Problem\n",
    "import fairnessMeasures\n",
    "#import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several protocols have been implemented. They can be accessed by importing the module protocols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r2': 53, 'r1': 15, 'r0': 93, 'r3': 83}\n",
      "agent 1{'r2': 88, 'r1': 89, 'r0': 77, 'r3': 55}\n",
      "agent 2{'r2': 59, 'r1': 17, 'r0': 27, 'r3': 36}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1 = Problem(3,4,'uniform',centralized=True)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation phase:\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0           ['r2', 'r1', 'r0', 'r3']\t244\n",
      "agent  1           ['r2', 'r1', 'r0', 'r3']\t309\n",
      "agent  2                                 []\t 0\n",
      "\n",
      "[(1.492, 'r2'), (1.528, 'r3'), (2.852, 'r0'), (5.235, 'r1')]\n",
      "Resource  r2  moves from  1  to  2\n",
      "Resource  r3  moves from  1  to  2\n",
      "Resource  r0  moves from  1  to  2\n",
      "Resource  r0  will be splitted!\n",
      "Agent  2  gets  0.317  of resource  r0\n",
      "Both agents get utility: 130.559\n"
     ]
    }
   ],
   "source": [
    "protocols.adjustedWinner(p1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you understand exactly why items are allocated this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r1': 0, 'r0': 0}\n",
      "agent 1{'r1': 75, 'r0': 25}\n",
      "agent 2{'r1': 25, 'r0': 75}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2 = Problem(3,2,'uniform',centralized=True)\n",
    "p2.setUtilities(\n",
    "[{'r0':0,'r1':0},\\\n",
    "{'r0':25,'r1':75},\\\n",
    "{'r0':75,'r1':25}]\n",
    ")\n",
    "print (p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a manipulation for agent 1, that is, a way to misrepresent the preference of the agent such that the utility is higher. Note that you will need to compute the allocation with the declared preferences, but that the actual utility enjoyed by agents must be computed with their 'true' preferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"best\" manipulation that agent 1 can do? \n",
    "To evaluate this, it will be useful to run a script trying all the different values possibly announced by agent 1, and to plot the utility obtained with each of these. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Winner for More than Two Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted Winner is just defined for two agents. Could you try to come up with a version fitting more than two agents? \n",
    "Taking inspiration from the code for 2 agents, could you implement and test your version? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 2 Picking Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r2': 0, 'r1': 0, 'r5': 0, 'r0': 0, 'r4': 0, 'r3': 0}\n",
      "agent 1{'r2': 5, 'r1': 2, 'r5': 2, 'r0': 1, 'r4': 7, 'r3': 3}\n",
      "agent 2{'r2': 8, 'r1': 6, 'r5': 2, 'r0': 2, 'r4': 1, 'r3': 1}\n",
      "agent 3{'r2': 4, 'r1': 4, 'r5': 2, 'r0': 5, 'r4': 2, 'r3': 3}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0['r2', 'r1', 'r5', 'r0', 'r4', 'r3']\t 0\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3 = Problem(4,6,'empty', centralized=True)\n",
    "p3.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print (p3)\n",
    "print (p3.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us apply a picking sequence on our problem p3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  1  picks  r4\n",
      "agent  2  picks  r2\n",
      "agent  3  picks  r0\n",
      "agent  2  picks  r1\n",
      "agent  3  picks  r3\n",
      "agent  1  picks  r5\n"
     ]
    }
   ],
   "source": [
    "s0 = [1,2,3,2,3,1]\n",
    "protocols.pickingSequence(p3,s0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                                 []\t 0\n",
      "agent  1                       ['r4', 'r5']\t 9\n",
      "agent  2                       ['r2', 'r1']\t14\n",
      "agent  3                       ['r0', 'r3']\t 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p3.printAllocation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(fairnessMeasures.envyMatrix(p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to generate standard sequences, like balanced or alternate ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the fairest picking sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider 3 agents and 5 items. Can you propose some sequence which would do well in terms of egalitarian social welfare? You can simulate a number of picking sequences by specifying: the number of experiments, the number of agents (remember to count agent 0 here-to be fixed sorry), the number of objects, the sequence, and the ways utilities are generated.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 2.986\n",
      "= Ratio of proportional:                 0.19\n",
      "= Ratio of envy free:                    0.057\n",
      "= Average number of envious:             1.145\n",
      "= Average max envy:                       4.42\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,1,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to conclude: \n",
    "For 3 agents, and 6 and 8 objects, could you find the fairest picking sequences in terms of: \n",
    "* egalitarian social welfare\n",
    "* average max envy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 7.625\n",
      "= Ratio of proportional:                 0.79\n",
      "= Ratio of envy free:                    0.489\n",
      "= Average number of envious:             0.585\n",
      "= Average max envy:                      1.461\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,6,[1,1,3,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The discussion and example about Adjusted Winner Manipulation is taken from a video by Eric Pacuit: \n",
    "https://www.youtube.com/watch?v=RtcnSXL69NQ\n",
    "\n",
    "* See (Bouveret and Lang, IJCAI-11) for more details about picking sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
