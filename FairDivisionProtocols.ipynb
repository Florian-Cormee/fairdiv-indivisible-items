{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Protocols for Fair Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import Problem\n",
    "import fairness_measures\n",
    "#import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several protocols have been implemented. They can be accessed by importing the module protocols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 80, 'r1': 4, 'r2': 31, 'r3': 59}\n",
      "agent 2{'r0': 72, 'r1': 76, 'r2': 97, 'r3': 69}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1 = Problem(3,4,'uniform',centralized=True)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                             ['r0']\t80\n",
      "agent  2                 ['r1', 'r2', 'r3']\t242\n",
      "\n",
      "[(1.169, 'r3'), (19.0, 'r1'), (3.129, 'r2')]\n",
      "Resource  r3  moves from  2  to  1\n",
      "Resource  r2  will be splitted!\n",
      "Agent  1  gets  0.266  of resource  r2\n",
      "Both agents get utility: 147.246\n"
     ]
    }
   ],
   "source": [
    "protocols.adjustedWinner(p1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you understand exactly why items are allocated this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 25, 'r1': 75}\n",
      "agent 2{'r0': 75, 'r1': 25}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2 = Problem(3,2,'uniform',centralized=True)\n",
    "p2.setUtilities(\n",
    "[{'r0':0,'r1':0},\\\n",
    "{'r0':25,'r1':75},\\\n",
    "{'r0':75,'r1':25}]\n",
    ")\n",
    "print (p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, the output of the adjusted winner protocol is rather obvious. Each agent gets its preferred item and everyone enjoys the same utility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                             ['r1']\t75\n",
      "agent  2                             ['r0']\t75\n",
      "\n",
      "[(3.0, 'r0')]\n"
     ]
    }
   ],
   "source": [
    "protocols.adjustedWinner(p2,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can you find a **manipulation** for agent 1, that is, a way to misrepresent the preferences of the agent (in other words, announce a valuation for an item which differs from the real one) such that the utility is in reality higher? \n",
    "Note that you will need to compute the allocation with the **declared** preferences, but that the actual utility enjoyed by agents must be computed with their **true** preferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"best\" manipulation that agent 1 can do? \n",
    "To evaluate this, it will be useful to run a script trying all the different values possibly announced by agent 1, and to plot the utility obtained with each of these. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 2 Picking Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3 = Problem(4,6,'empty', centralized=True)\n",
    "p3.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print (p3)\n",
    "print (p3.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us apply a picking sequence on our problem p3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  1  picks  r4\n",
      "agent  2  picks  r2\n",
      "agent  3  picks  r0\n",
      "agent  2  picks  r1\n",
      "agent  3  picks  r3\n",
      "agent  1  picks  r5\n"
     ]
    }
   ],
   "source": [
    "s0 = [1,2,3,2,3,1]\n",
    "protocols.pickingSequence(p3,s0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctioneer                                  []\t\n",
      "agent  1                       ['r4', 'r5']\t 9\n",
      "agent  2                       ['r2', 'r1']\t14\n",
      "agent  3                       ['r0', 'r3']\t 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p3.printAllocation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(fairness_measures.envyMatrix(p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to generate standard sequences, like balanced or alternate ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the fairest picking sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider 3 agents and 5 items. Can you propose some sequence which would do well in terms of egalitarian social welfare? You can simulate a number of picking sequences by specifying: the number of experiments, the number of agents (remember to count agent 0 here-to be fixed sorry), the number of objects, the sequence, and the ways utilities are generated.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                  3.02\n",
      "= Ratio of proportional:                0.201\n",
      "= Ratio of envy free:                    0.055\n",
      "= Average number of envious:             1.129\n",
      "= Average max envy:                      4.352\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,1,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to conclude: \n",
    "For 3 agents, and 6 and 8 objects, could you find the fairest picking sequences in terms of: \n",
    "* egalitarian social welfare\n",
    "* average max envy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 7.581\n",
      "= Ratio of proportional:                0.796\n",
      "= Ratio of envy free:                    0.476\n",
      "= Average number of envious:             0.615\n",
      "= Average max envy:                      1.507\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,6,[1,1,3,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Lipton et al. protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now test the protocol of Lipton, which allocates items one by one and solves envy cycles when they occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 2{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 3{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Running the Lipton et al. protocol\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: []}\n",
      "allocating resource  r0\n",
      "auctioneer      ['r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [1], 3: [1]}\n",
      "allocating resource  r1\n",
      "auctioneer            ['r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r2\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                             ['r2']\t 4\n",
      "\n",
      "envy graph: {0: [], 1: [2, 3], 2: [3], 3: [1]}\n",
      "solving the cycle: []\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r1']\t 2\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "allocating resource  r3\n",
      "auctioneer                        ['r4', 'r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: [1]}\n",
      "allocating resource  r4\n",
      "auctioneer                              ['r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r5\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "Final allocation:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                       ['r0', 'r5']\t 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Problem(4,6,'empty','centralized')\n",
    "print(p4)\n",
    "print(p4.printAllocation())\n",
    "p4.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print(p4)\n",
    "\n",
    "protocols.lipton(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Local deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us play a bit with local exchanges. For this, we will need to create a decentralized MARA problem. Items are intially allocated at random among agents. Here, utilities are Borda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 4, 'r1': 5, 'r2': 2, 'r3': 6, 'r4': 1, 'r5': 3}\n",
      "agent 1{'r0': 6, 'r1': 2, 'r2': 5, 'r3': 4, 'r4': 3, 'r5': 1}\n",
      "agent 2{'r0': 5, 'r1': 6, 'r2': 1, 'r3': 4, 'r4': 2, 'r5': 3}\n",
      "agent 3{'r0': 5, 'r1': 2, 'r2': 4, 'r3': 1, 'r4': 3, 'r5': 6}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r4']\t 1\n",
      "agent  1                             ['r1']\t 2\n",
      "agent  2                       ['r2', 'r3']\t 5\n",
      "agent  3                       ['r0', 'r5']\t11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p5 = Problem(4,6,'borda',centralized=False)\n",
    "print(p5)\n",
    "print(p5.printAllocation())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot which agents could perform mutually beneficial deals? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  0  meets agent  1\n",
      "deal between  0  and  1 for  r4  and  r1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r1']\t 5\n",
      "agent  1                             ['r4']\t 3\n",
      "agent  2                       ['r2', 'r3']\t 5\n",
      "agent  3                       ['r0', 'r5']\t11\n",
      "\n",
      "agent  0  meets agent  1\n",
      "agent  0  meets agent  3\n",
      "agent  1  meets agent  2\n",
      "deal between  1  and  2 for  r4  and  r2\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r1']\t 5\n",
      "agent  1                             ['r2']\t 5\n",
      "agent  2                       ['r3', 'r4']\t 6\n",
      "agent  3                       ['r0', 'r5']\t11\n",
      "\n",
      "agent  1  meets agent  2\n",
      "agent  1  meets agent  3\n",
      "agent  0  meets agent  1\n",
      "agent  0  meets agent  3\n",
      "agent  2  meets agent  3\n",
      "agent  0  meets agent  2\n",
      "deal between  0  and  2 for  r1  and  r3\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r3']\t 6\n",
      "agent  1                             ['r2']\t 5\n",
      "agent  2                       ['r4', 'r1']\t 8\n",
      "agent  3                       ['r0', 'r5']\t11\n",
      "\n",
      "agent  2  meets agent  3\n",
      "agent  0  meets agent  3\n",
      "agent  1  meets agent  3\n",
      "agent  0  meets agent  1\n",
      "agent  1  meets agent  2\n",
      "agent  0  meets agent  2\n",
      "End of dynamics. No more deal possible.\n"
     ]
    }
   ],
   "source": [
    "protocols.randomDynamics(p5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the envy of the final allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [3], 1: [3], 2: [], 3: []}\n"
     ]
    }
   ],
   "source": [
    "m = fairness_measures.envyMatrix(p5)\n",
    "g = fairness_measures.buildEnvyGraph(m)\n",
    "print (g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Could you find fairer dynamics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, agents just meet randomly (a given pair is picked uniformly among the possible ones). \n",
    "Could you conceive a fairer dynamics and test it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The discussion and example about Adjusted Winner Manipulation is taken from a video by Eric Pacuit: \n",
    "https://www.youtube.com/watch?v=RtcnSXL69NQ\n",
    "\n",
    "* See (Bouveret and Lang, IJCAI-11) for more details about picking sequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notebook last updated 2020-01-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
